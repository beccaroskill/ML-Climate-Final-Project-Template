{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PrepDataset.ipynb","provenance":[],"authorship_tag":"ABX9TyPfDMCEimYhtoO4hXMhvmjM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ApD5EPho6Jgv"},"outputs":[],"source":["from tensorflow.keras import layers\n","from tensorflow import keras\n","import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y1H-Vz7b6aGR"},"outputs":[],"source":["import tensorflow as tf\n","INPUT_WIDTH = 128\n","INPUT_HEIGHT = 128\n","N_CHANNELS = 12\n","N_CLASSES = 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iPHIoxO-W3sr"},"outputs":[],"source":["import uuid\n","\n","def load_dir(data_dir):\n","  id_img_map = {}\n","  fire_sample_map = {}\n","  for f in os.listdir(data_dir):\n","    if '_' in f and not 'download_log' in f:\n","      id = f[:f.index('_')]\n","      if id in fire_sample_map:\n","        id_img_map[fire_sample_map[id]].append(f'{data_dir}{f}')\n","      else:\n","        fire_sample_map[id] = str(uuid.uuid4())\n","        id_img_map[fire_sample_map[id]] = [f'{data_dir}{f}']\n","  return id_img_map"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_h-a7vsNhrK"},"outputs":[],"source":["id_img_map_negative = load_dir('data/TrainingData/AllData/Fire-Negative-5mo/')\n","id_img_map_positive = load_dir('data/TrainingData/AllData/Fire-Positive-5mo/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QTmMwegmZqrg"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","SIZE = 2769\n","all_ids_negative = list(zip(id_img_map_negative.keys(), [0]*SIZE))\n","all_ids_positive = list(zip(id_img_map_positive.keys(), [1]*SIZE))\n","all_ids = all_ids_negative + all_ids_positive\n","ids_train, ids_test = train_test_split(all_ids, test_size=0.2, random_state=42)\n","ids_train, ids_val = train_test_split(ids_train, test_size=0.25, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hYKf0IOXbrsE"},"outputs":[],"source":["def batch(iterable, n=1):\n","    l = len(iterable)\n","    for ndx in range(0, l, n):\n","        yield iterable[ndx:min(ndx + n, l)]\n","\n","BATCH_SIZE = 32\n","train_batch_ids = list(batch(ids_train, BATCH_SIZE))\n","val_batch_ids = list(batch(ids_val, BATCH_SIZE))\n","test_batch_ids = list(batch(ids_test, BATCH_SIZE))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OZngJnL-2R5m"},"outputs":[],"source":["def scale_resize_image(image):\n","    image = tf.image.convert_image_dtype(image, tf.float32) # equivalent to dividing image pixels by 255\n","    image = tf.image.resize(image, (INPUT_WIDTH, INPUT_HEIGHT)) # Resizing the image to 224x224 dimention\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"atZP6gmTdX_F"},"outputs":[],"source":["def get_image_data(id_img_map, sample_id):\n","  images = []\n","  fs = id_img_map[sample_id]\n","  for i,f in enumerate(fs[::-1]): # Reverse reversed time\n","    image = np.load(f)\n","    image_resized = scale_resize_image(image)\n","    images.append(image_resized)\n","  input = np.array(images)\n","  return input"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":166809,"status":"ok","timestamp":1649887193282,"user":{"displayName":"Becca Roskill","userId":"04960640904937147322"},"user_tz":240},"id":"9PK1SJLcb9Qg","outputId":"2d1a8579-54d1-4986-b529-7051a9e3c11d"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 104/104 [02:46<00:00,  1.60s/it]\n"]}],"source":["from tqdm import tqdm\n","\n","def get_batch_data(batch):\n","  X = []\n","  y = []\n","  for sample_id, label in batch:\n","    id_img_map = id_img_map_positive if label==1 else id_img_map_negative\n","    x = get_image_data(id_img_map, sample_id)\n","    X.append(x)\n","    y.append(label)\n","  X = np.array(X)\n","  y = np.array(y)\n","  return X, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yc3RgUHY5HHA"},"outputs":[],"source":["def save_dataset(dataset, name):\n","  for i, batch in enumerate(dataset):\n","    X,y = batch\n","    with open(f'data/TrainingData/{name}/{i}_X.npy', 'wb') as f:\n","      np.save(f, X)\n","    with open(f'data/TrainingData/{name}/{i}_y.npy', 'wb') as f:\n","      np.save(f, y)"]},{"cell_type":"code","source":["train_data = []\n","for batch in tqdm(train_batch_ids):\n","  X, y = get_batch_data(batch)\n","  train_data += [[X,y]]"],"metadata":{"id":"nu-TlZL4anXj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2_pqPxZ_asdG"},"outputs":[],"source":["save_dataset(train_data, 'train')"]},{"cell_type":"code","source":["val_data = []\n","for batch in tqdm(val_batch_ids):\n","  X, y = get_batch_data(batch)\n","  val_data += [[X,y]]"],"metadata":{"id":"Wmh4byyRatz3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L1PQKLYVatz4"},"outputs":[],"source":["save_dataset(val_data, 'val')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":874105,"status":"ok","timestamp":1649891022796,"user":{"displayName":"Becca Roskill","userId":"04960640904937147322"},"user_tz":240},"id":"cZ6cxdiB5X0O","outputId":"37ec053b-2bb6-4de7-8337-83803942f4d1"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 35/35 [14:33<00:00, 24.97s/it]\n"]}],"source":["test_data = []\n","for batch in tqdm(test_batch_ids):\n","  X, y = get_batch_data(batch)\n","  test_data += [[X,y]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KT9a6AUkE7VY"},"outputs":[],"source":["save_dataset(test_data, 'test')"]},{"cell_type":"code","source":["class My_Custom_Generator(keras.utils.Sequence) :\n","  \n","  def __init__(self, image_filenames, labels, batch_size) :\n","    self.image_filenames = image_filenames\n","    self.labels = labels\n","    self.batch_size = batch_size\n","    \n","    \n","  def __len__(self) :\n","    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n","  \n","  \n","  def __getitem__(self, idx) :\n","    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n","    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n","    \n","    return np.array([\n","            resize(imread('/content/all_images/' + str(file_name)), (80, 80, 3))\n","               for file_name in batch_x])/255.0, np.array(batch_y)"],"metadata":{"id":"7px9pmMgDMOH"},"execution_count":null,"outputs":[]}]}