{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/ML-Climate-Predicting-Wildfires/src')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_aAAqJkXBXJ",
        "outputId": "083c04ac-31b0-472f-a0ac-4db80a27f250"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# tfds.disable_progress_bar()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ApD5EPho6Jgv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "INPUT_WIDTH = 128\n",
        "INPUT_HEIGHT = 128\n",
        "N_CHANNELS = 12\n",
        "N_CLASSES = 2"
      ],
      "metadata": {
        "id": "y1H-Vz7b6aGR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dir(data_dir):\n",
        "  id_img_map = {}\n",
        "\n",
        "  for f in os.listdir(data_dir):\n",
        "    if '_' in f and not 'download_log' in f:\n",
        "      id = f[:f.index('_')]\n",
        "      if id in id_img_map:\n",
        "        id_img_map[id].append(f)\n",
        "      else:\n",
        "        id_img_map[id] = [f]\n",
        "  return id_img_map\n",
        "\n",
        "data_dir = \"data/TrainingData/Fire-Positive-5mo/\""
      ],
      "metadata": {
        "id": "iPHIoxO-W3sr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_resize_image(image):\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32) # equivalent to dividing image pixels by 255\n",
        "    image = tf.image.resize(image, (INPUT_WIDTH, INPUT_HEIGHT)) # Resizing the image to 224x224 dimention\n",
        "    return image"
      ],
      "metadata": {
        "id": "OZngJnL-2R5m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def load_dataset(id_img_map):\n",
        "  images = []\n",
        "  for id, fs in tqdm(list(id_img_map.items())):\n",
        "    for i,f in enumerate(fs[::-1]): # Reverse reversed time\n",
        "      image = np.load(data_dir + f)\n",
        "      image_resized = scale_resize_image(image)\n",
        "      images.append(image_resized)\n",
        "  return np.array(images)"
      ],
      "metadata": {
        "id": "u0fSePiDXihk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_ig_map = load_dir(data_dir)"
      ],
      "metadata": {
        "id": "04qxtUe8YTeM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_positive = load_dataset(id_ig_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncyrr_ebYsTj",
        "outputId": "007cbd96-aba4-42bb-a1ac-ccb3d3f9dd73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 2259/2633 [05:34<01:43,  3.60it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_positive.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShmPQSxnYvG1",
        "outputId": "4c806d23-ac75-4bba-83d8-76f16446586d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], dtype=float64)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0LeaxB94Zkov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u1EyFRKRZkrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aI_aH7fnZkus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('{}/Fire-Positive-Dataset.npy'.format(data_dir), 'wb') as f:\n",
        "  np.save(f, positive_X)"
      ],
      "metadata": {
        "id": "2y8mwPT-eJB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "data_dir = 'data/TrainingData/Fire-Positive-New'\n",
        "positive_X = np.load('{}/Fire-Positive-Dataset.npy'.format(data_dir))"
      ],
      "metadata": {
        "id": "UVUUKRpzfow5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_Y = np.ones((positive_X.shape[0], 1))\n",
        "positive_Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLQ9ZnMnGi3y",
        "outputId": "00eef1ff-43c1-4b00-a271-dff2ae3f59d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4504, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'data/TrainingData/Fire-Negative'\n",
        "print(len(os.listdir(data_dir)))\n",
        "negative_data = []\n",
        "for f in os.listdir(data_dir):\n",
        "  if '.npy' in f:\n",
        "    arr = np.load('{}/{}'.format(data_dir, f))\n",
        "    image = scale_resize_image(arr)\n",
        "    negative_data.append(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYlfYrR_HlXE",
        "outputId": "1d0c5814-70fb-4be8-fd07-a337a8df6539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "negative_X = np.array(negative_data)\n",
        "negative_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ceeb98-e582-415d-f1b2-001a24884014",
        "id": "31oJWNkNHlXO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1318, 200, 200, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('{}/Fire-Negative-Dataset.npy'.format(data_dir), 'wb') as f:\n",
        "  np.save(f, negative_X)"
      ],
      "metadata": {
        "id": "mZbEcxpyfMEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'data/TrainingData/Fire-Negative'\n",
        "negative_X = np.load('{}/Fire-Negative-Dataset.npy'.format(data_dir))"
      ],
      "metadata": {
        "id": "v34HaWWugIRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_Y = np.zeros((negative_X.shape[0], 1))\n",
        "negative_Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "954e2c33-4771-4768-8d08-58cc6e812b03",
        "id": "zI_pyYBJHlXO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1318, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate((positive_X[:negative_X.shape[0]], negative_X), axis=0)\n",
        "y = np.concatenate((positive_Y[:negative_Y.shape[0]], negative_Y), axis=0)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOdRiNBxIKjq",
        "outputId": "51423696-5b26-41a0-825a-4de847c00393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2636, 200, 200, 7), (2636, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('data/TrainingData/DatasetX.npy', 'wb') as f:\n",
        "  np.save(f, X)\n",
        "with open('data/TrainingData/DatasetY.npy', 'wb') as f:\n",
        "  np.save(f, y)"
      ],
      "metadata": {
        "id": "R85PC-j1hmWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "X = np.load('data/TrainingData/DatasetX.npy')\n",
        "y = np.load('data/TrainingData/DatasetY.npy')"
      ],
      "metadata": {
        "id": "eGhXWw9zilrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
      ],
      "metadata": {
        "id": "BF0UF2l7I9-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "val = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "test = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "tf.data.experimental.save(\n",
        "    train, 'data/TrainingData/train', compression=None, shard_func=None, checkpoint_args=None\n",
        ")\n",
        "tf.data.experimental.save(\n",
        "    val, 'data/TrainingData/val', compression=None, shard_func=None, checkpoint_args=None\n",
        ")\n",
        "tf.data.experimental.save(\n",
        "    test, 'data/TrainingData/test', compression=None, shard_func=None, checkpoint_args=None\n",
        ")"
      ],
      "metadata": {
        "id": "tk1OrUT2JgVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = tf.data.experimental.load(\n",
        "    'data/TrainingData/train', element_spec=None, compression=None, reader_func=None\n",
        ")\n",
        "\n",
        "val = tf.data.experimental.load(\n",
        "    'data/TrainingData/val', element_spec=None, compression=None, reader_func=None\n",
        ")\n",
        "\n",
        "test = tf.data.experimental.load(\n",
        "    'data/TrainingData/test', element_spec=None, compression=None, reader_func=None\n",
        ")"
      ],
      "metadata": {
        "id": "Uqxec3L7p4JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 5\n",
        "SHUFFLE_BUFFER_SIZE = 10\n",
        "\n",
        "train = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "val = val.batch(BATCH_SIZE)\n",
        "test = test.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "rSVTkNTbK8GU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, BatchNormalization, \\\n",
        "    MaxPool2D, GlobalMaxPool2D\n",
        "def build_convnet(shape=(INPUT_WIDTH, INPUT_HEIGHT, N_CHANNELS)):\n",
        "    momentum = .9\n",
        "    model = keras.Sequential()\n",
        "    model.add(Conv2D(64, (3,3), input_shape=shape,\n",
        "        padding='same', activation='relu'))\n",
        "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # model.add(MaxPool2D())\n",
        "    \n",
        "    # model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # model.add(MaxPool2D())\n",
        "    \n",
        "    # model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # model.add(MaxPool2D())\n",
        "    \n",
        "    # model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # # flatten...\n",
        "    # model.add(GlobalMaxPool2D())\n",
        "    return model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5cByDMJEmhO",
        "outputId": "b5d303d3-e277-4a16-c3c1-4417c03403c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/applications/mobilenet_v2.py:285: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels.\n",
            "  weights=weights)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, GRU, Dense, Dropout\n",
        "\n",
        "def action_model(shape=(6, INPUT_WIDTH, INPUT_HEIGHT, N_CHANNELS), nbout=2):\n",
        "    # Create our convnet with (128, 128, 12) input shape\n",
        "    convnet = build_convnet(shape[1:])\n",
        "    \n",
        "    # then create our final model\n",
        "    model = keras.Sequential()\n",
        "    # add the convnet with (6, 128, 128, 12) shape\n",
        "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
        "    # here, you can also use GRU or LSTM\n",
        "    model.add(LSTM(64))\n",
        "    model.add(Dropout(.3))\n",
        "    # and finally, we make a decision network\n",
        "    model.add(Dense(264, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(nbout, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "NBFRAME = 6\n",
        "INSHAPE=(NBFRAME,) + (INPUT_WIDTH, INPUT_HEIGHT) + (N_CHANNELS,) # (6, 128, 128, 12)\n",
        "model = action_model(INSHAPE, len(classes), nbout=1)\n",
        "optimizer = keras.optimizers.Adam(0.001)\n",
        "model.compile(\n",
        "    optimizer,\n",
        "    'binary_crossentropy',\n",
        "    metrics=['acc']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cuFOO-2qX1_",
        "outputId": "ff51d55c-dce9-49ee-f0bb-f67d980fa60a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 198, 198, 16)      1024      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 99, 99, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 97, 97, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 48, 48, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 46, 46, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 23, 23, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 21, 21, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 623,329\n",
            "Trainable params: 623,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "optimizer=RMSprop(lr=0.001),\n",
        "metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hryKEnDjtx8E",
        "outputId": "c00fc8ce-4b86-4da6-ba5f-703fabad48e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LozT-n_Nx2Lz",
        "outputId": "a73c57fa-b1f7-47ae-bbdf-244de15ded4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "317"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train,\n",
        "steps_per_epoch=10,\n",
        "epochs=30,\n",
        "verbose=1,\n",
        "validation_data = val,\n",
        "validation_steps=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn_4I8_2uJ_-",
        "outputId": "1ffaa6e7-863d-4dfc-b917-52e2d3373be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "10/10 [==============================] - 8s 805ms/step - loss: 0.7371 - accuracy: 0.6600 - precision: 0.6957 - recall: 0.6154 - val_loss: 0.6282 - val_accuracy: 0.6500 - val_precision: 0.8889 - val_recall: 0.5714\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 5s 551ms/step - loss: 0.6208 - accuracy: 0.7200 - precision: 0.7727 - recall: 0.6538 - val_loss: 0.5084 - val_accuracy: 0.7500 - val_precision: 0.7812 - val_recall: 0.8929\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 6s 585ms/step - loss: 0.6711 - accuracy: 0.6600 - precision: 0.6667 - recall: 0.8667 - val_loss: 0.5450 - val_accuracy: 0.7250 - val_precision: 0.8696 - val_recall: 0.7143\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 5s 558ms/step - loss: 0.7017 - accuracy: 0.6400 - precision: 0.5333 - recall: 0.4211 - val_loss: 0.5789 - val_accuracy: 0.7750 - val_precision: 0.9130 - val_recall: 0.7500\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 6s 566ms/step - loss: 0.6545 - accuracy: 0.6000 - precision: 0.4667 - recall: 0.3684 - val_loss: 0.6085 - val_accuracy: 0.6750 - val_precision: 0.8947 - val_recall: 0.6071\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 6s 626ms/step - loss: 0.6988 - accuracy: 0.6000 - precision: 0.5714 - recall: 0.5217 - val_loss: 0.6393 - val_accuracy: 0.6500 - val_precision: 0.8889 - val_recall: 0.5714\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 5s 536ms/step - loss: 0.6581 - accuracy: 0.6400 - precision: 0.7143 - recall: 0.5556 - val_loss: 0.6563 - val_accuracy: 0.5500 - val_precision: 0.8571 - val_recall: 0.4286\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 5s 546ms/step - loss: 0.6601 - accuracy: 0.6400 - precision: 0.7222 - recall: 0.5000 - val_loss: 0.6389 - val_accuracy: 0.5750 - val_precision: 0.8667 - val_recall: 0.4643\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 6s 561ms/step - loss: 0.6353 - accuracy: 0.6400 - precision: 0.7273 - recall: 0.3478 - val_loss: 0.7309 - val_accuracy: 0.5000 - val_precision: 0.8333 - val_recall: 0.3571\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 6s 567ms/step - loss: 0.7352 - accuracy: 0.5800 - precision: 0.7273 - recall: 0.5161 - val_loss: 0.5437 - val_accuracy: 0.7500 - val_precision: 0.8750 - val_recall: 0.7500\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 6s 602ms/step - loss: 0.6475 - accuracy: 0.6400 - precision: 0.7083 - recall: 0.6071 - val_loss: 0.5559 - val_accuracy: 0.7000 - val_precision: 0.8636 - val_recall: 0.6786\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 7s 720ms/step - loss: 0.6925 - accuracy: 0.6800 - precision: 0.6818 - recall: 0.6250 - val_loss: 0.5717 - val_accuracy: 0.7000 - val_precision: 0.9000 - val_recall: 0.6429\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 6s 616ms/step - loss: 0.6281 - accuracy: 0.6400 - precision: 0.7600 - recall: 0.6129 - val_loss: 0.5441 - val_accuracy: 0.7250 - val_precision: 0.8696 - val_recall: 0.7143\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 6s 600ms/step - loss: 0.6358 - accuracy: 0.6400 - precision: 0.6667 - recall: 0.7143 - val_loss: 0.5679 - val_accuracy: 0.6750 - val_precision: 0.8947 - val_recall: 0.6071\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 6s 582ms/step - loss: 0.6102 - accuracy: 0.6800 - precision: 0.7778 - recall: 0.5385 - val_loss: 0.5287 - val_accuracy: 0.7500 - val_precision: 0.8214 - val_recall: 0.8214\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 6s 636ms/step - loss: 0.7922 - accuracy: 0.6400 - precision: 0.6957 - recall: 0.5926 - val_loss: 0.5903 - val_accuracy: 0.6500 - val_precision: 0.8889 - val_recall: 0.5714\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 6s 605ms/step - loss: 0.6337 - accuracy: 0.6600 - precision: 0.6667 - recall: 0.5217 - val_loss: 0.6090 - val_accuracy: 0.7000 - val_precision: 0.9000 - val_recall: 0.6429\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 6s 618ms/step - loss: 0.6208 - accuracy: 0.7200 - precision: 0.8235 - recall: 0.5600 - val_loss: 0.5386 - val_accuracy: 0.6500 - val_precision: 0.7692 - val_recall: 0.7143\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 6s 625ms/step - loss: 0.6898 - accuracy: 0.6400 - precision: 0.6800 - recall: 0.6296 - val_loss: 0.5468 - val_accuracy: 0.6750 - val_precision: 0.7778 - val_recall: 0.7500\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 9s 939ms/step - loss: 0.6732 - accuracy: 0.6400 - precision: 0.5862 - recall: 0.7391 - val_loss: 0.6733 - val_accuracy: 0.6750 - val_precision: 0.8947 - val_recall: 0.6071\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 6s 513ms/step - loss: 0.6653 - accuracy: 0.6200 - precision: 0.6316 - recall: 0.5000 - val_loss: 0.5723 - val_accuracy: 0.7000 - val_precision: 0.9000 - val_recall: 0.6429\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 5s 544ms/step - loss: 0.5961 - accuracy: 0.7000 - precision: 0.7333 - recall: 0.5000 - val_loss: 0.5350 - val_accuracy: 0.7750 - val_precision: 0.9130 - val_recall: 0.7500\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 5s 513ms/step - loss: 0.5609 - accuracy: 0.7400 - precision: 0.8077 - recall: 0.7241 - val_loss: 0.5809 - val_accuracy: 0.7000 - val_precision: 0.9000 - val_recall: 0.6429\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 4s 443ms/step - loss: 0.6236 - accuracy: 0.6800 - precision: 0.7647 - recall: 0.5200 - val_loss: 0.5353 - val_accuracy: 0.7500 - val_precision: 0.8750 - val_recall: 0.7500\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 4s 451ms/step - loss: 0.5202 - accuracy: 0.7400 - precision: 0.7600 - recall: 0.7308 - val_loss: 0.5754 - val_accuracy: 0.7500 - val_precision: 0.9091 - val_recall: 0.7143\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 4s 446ms/step - loss: 0.7379 - accuracy: 0.6800 - precision: 0.7083 - recall: 0.6538 - val_loss: 0.5251 - val_accuracy: 0.7500 - val_precision: 0.8462 - val_recall: 0.7857\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 4s 450ms/step - loss: 0.5898 - accuracy: 0.7400 - precision: 0.7500 - recall: 0.7200 - val_loss: 0.5673 - val_accuracy: 0.7000 - val_precision: 0.8636 - val_recall: 0.6786\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 4s 415ms/step - loss: 0.7197 - accuracy: 0.6800 - precision: 0.5714 - recall: 0.4444 - val_loss: 0.6069 - val_accuracy: 0.7500 - val_precision: 0.8750 - val_recall: 0.7500\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 4s 452ms/step - loss: 0.6612 - accuracy: 0.6800 - precision: 0.6522 - recall: 0.6522 - val_loss: 0.6259 - val_accuracy: 0.6750 - val_precision: 0.8947 - val_recall: 0.6071\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 4s 428ms/step - loss: 0.6236 - accuracy: 0.6800 - precision: 0.6667 - recall: 0.6667 - val_loss: 0.5316 - val_accuracy: 0.7250 - val_precision: 0.7576 - val_recall: 0.8929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, precision, recall = model.evaluate(test, verbose=0)"
      ],
      "metadata": {
        "id": "-KHm7hK9ucbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, precision, recall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GckL_GnuxlGO",
        "outputId": "f927adf3-d74a-49ca-869a-159ea126ba4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5874483585357666,\n",
              " 0.6931818127632141,\n",
              " 0.8137931227684021,\n",
              " 0.46640315651893616)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Medium article](https://medium.com/smileinnovation/training-neural-network-with-image-sequence-an-example-with-video-as-input-c3407f7a0b0f)"
      ],
      "metadata": {
        "id": "NIgBKhQfxEus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.layers import TimeDistributed, GRU, Dense, Dropout\n",
        "# def action_model(shape=(5, 112, 112, 3), nbout=3):\n",
        "#     # Create our convnet with (112, 112, 3) input shape\n",
        "#     convnet = build_convnet(shape[1:])\n",
        "    \n",
        "#     # then create our final model\n",
        "#     model = keras.Sequential()\n",
        "#     # add the convnet with (5, 112, 112, 3) shape\n",
        "#     model.add(TimeDistributed(convnet, input_shape=shape))\n",
        "#     # here, you can also use GRU or LSTM\n",
        "#     model.add(GRU(64))\n",
        "#     # and finally, we make a decision network\n",
        "#     model.add(Dense(1024, activation='relu'))\n",
        "#     model.add(Dropout(.5))\n",
        "#     model.add(Dense(512, activation='relu'))\n",
        "#     model.add(Dropout(.5))\n",
        "#     model.add(Dense(128, activation='relu'))\n",
        "#     model.add(Dropout(.5))\n",
        "#     model.add(Dense(64, activation='relu'))\n",
        "#     model.add(Dense(nbout, activation='softmax'))\n",
        "#     return model\n"
      ],
      "metadata": {
        "id": "3WNZCFI-zveg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh6g2l8Fwxnw"
      },
      "outputs": [],
      "source": [
        "# INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (5, 112, 112, 3)\n",
        "# model = action_model(INSHAPE, len(classes))\n",
        "optimizer = keras.optimizers.Adam(0.001)\n",
        "model.compile(\n",
        "    optimizer,\n",
        "    'binary_crossentropy',\n",
        "    metrics=['acc']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=50\n",
        "# create a \"chkp\" directory before to run that\n",
        "# because ModelCheckpoint will write models inside\n",
        "callbacks = [\n",
        "    keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        'chkp/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
        "        verbose=1),\n",
        "]\n",
        "model.fit_generator(\n",
        "    train,\n",
        "    validation_data=val,\n",
        "    verbose=1,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "LJw0KUHazZPX",
        "outputId": "d2f087f8-ffd5-43a2-a017-dae0bdabaa8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "210/210 [==============================] - ETA: 0s - loss: 6.5130 - acc: 0.4279\n",
            "Epoch 1: saving model to chkp/weights.01-5.81.hdf5\n",
            "210/210 [==============================] - 234s 1s/step - loss: 6.5130 - acc: 0.4279 - val_loss: 5.8113 - val_acc: 0.3811 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "210/210 [==============================] - ETA: 0s - loss: 6.5104 - acc: 0.4269\n",
            "Epoch 2: saving model to chkp/weights.02-5.81.hdf5\n",
            "210/210 [==============================] - 235s 1s/step - loss: 6.5104 - acc: 0.4269 - val_loss: 5.8113 - val_acc: 0.3811 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "210/210 [==============================] - ETA: 0s - loss: 6.5104 - acc: 0.4269\n",
            "Epoch 3: saving model to chkp/weights.03-5.81.hdf5\n",
            "210/210 [==============================] - 231s 1s/step - loss: 6.5104 - acc: 0.4269 - val_loss: 5.8113 - val_acc: 0.3811 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "210/210 [==============================] - ETA: 0s - loss: 6.5104 - acc: 0.4269\n",
            "Epoch 4: saving model to chkp/weights.04-5.81.hdf5\n",
            "210/210 [==============================] - 222s 1s/step - loss: 6.5104 - acc: 0.4269 - val_loss: 5.8113 - val_acc: 0.3811 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "210/210 [==============================] - ETA: 0s - loss: 6.5104 - acc: 0.4269\n",
            "Epoch 5: saving model to chkp/weights.05-5.81.hdf5\n",
            "210/210 [==============================] - 224s 1s/step - loss: 6.5104 - acc: 0.4269 - val_loss: 5.8113 - val_acc: 0.3811 - lr: 0.0010\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-0330a2645c90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TVvRKlqmWwSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "Xq1zZ1d9LszW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mobilenet(shape=(224, 224, 3), nbout=3):\n",
        "    model = keras.applications.mobilenet.MobileNet(\n",
        "        include_top=False,\n",
        "        input_shape=shape,\n",
        "        weights='imagenet')\n",
        "    # Keep 9 layers to train﻿﻿\n",
        "    trainable = 9\n",
        "    for layer in model.layers[:-trainable]:\n",
        "        layer.trainable = False\n",
        "    for layer in model.layers[-trainable:]:\n",
        "        layer.trainable = True\n",
        "    output = keras.GlobalMaxPool2D()\n",
        "    return keras.Sequential([model, output])"
      ],
      "metadata": {
        "id": "yKcpQppS0K4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set size to 224, 224\n",
        "SIZE = (224, 224)\n",
        "CHANNELS = 3\n",
        "NBFRAME = 5\n",
        "BS = 8"
      ],
      "metadata": {
        "id": "lmqClG_w0VHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def action_model(shape=(5, 112, 112, 3), nbout=3):\n",
        "    # Create our convnet with (112, 112, 3) input shape\n",
        "    convnet = build_mobilenet(shape[1:])\n",
        "    \n",
        "    # then create our final model\n",
        "    model = keras.Sequential()\n",
        "    # add the convnet with (5, 112, 112, 3) shape\n",
        "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
        "    # here, you can also use GRU or LSTM\n",
        "    model.add(GRU(64))\n",
        "    # and finally, we make a decision network\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(nbout, activation='softmax'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "gMhQWZVA0bEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (5, 224, 224, 3)\n",
        "model = action_model(INSHAPE, len(classes))\n",
        "optimizer = keras.optimizers.SGD()\n",
        "model.compile(\n",
        "    optimizer,\n",
        "    'categorical_crossentropy',\n",
        "    metrics=['acc']\n",
        ")"
      ],
      "metadata": {
        "id": "o-52R8OH0jOk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}