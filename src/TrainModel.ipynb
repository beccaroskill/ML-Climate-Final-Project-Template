{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_aAAqJkXBXJ",
        "outputId": "4f1a4399-5ebc-4e81-dd9b-09e470a39075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/ML-Climate-Predicting-Wildfires/src')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ApD5EPho6Jgv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# tfds.disable_progress_bar()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "y1H-Vz7b6aGR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "INPUT_WIDTH = 128\n",
        "INPUT_HEIGHT = 128\n",
        "N_CHANNELS = 12\n",
        "N_CLASSES = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iPHIoxO-W3sr"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "def load_dir(data_dir):\n",
        "  id_img_map = {}\n",
        "  fire_sample_map = {}\n",
        "  for f in os.listdir(data_dir):\n",
        "    if '_' in f and not 'download_log' in f:\n",
        "      id = f[:f.index('_')]\n",
        "      if id in fire_sample_map:\n",
        "        id_img_map[fire_sample_map[id]].append(f'{data_dir}{f}')\n",
        "      else:\n",
        "        fire_sample_map[id] = str(uuid.uuid4())\n",
        "        id_img_map[fire_sample_map[id]] = [f'{data_dir}{f}']\n",
        "  return id_img_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u_h-a7vsNhrK"
      },
      "outputs": [],
      "source": [
        "id_img_map_negative = load_dir('data/TrainingData/AllData/Fire-Negative-5mo/')\n",
        "id_img_map_positive = load_dir('data/TrainingData/AllData/Fire-Positive-5mo/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QTmMwegmZqrg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SIZE = 2769\n",
        "all_ids_negative = list(zip(id_img_map_negative.keys(), [0]*SIZE))\n",
        "all_ids_positive = list(zip(id_img_map_positive.keys(), [1]*SIZE))\n",
        "all_ids = all_ids_negative + all_ids_positive\n",
        "ids_train, ids_test = train_test_split(all_ids, test_size=0.2, random_state=42)\n",
        "ids_train, ids_val = train_test_split(ids_train, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hYKf0IOXbrsE"
      },
      "outputs": [],
      "source": [
        "def batch(iterable, n=1):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, n):\n",
        "        yield iterable[ndx:min(ndx + n, l)]\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_batch_ids = list(batch(ids_train, BATCH_SIZE))\n",
        "val_batch_ids = list(batch(ids_val, BATCH_SIZE))\n",
        "test_batch_ids = list(batch(ids_test, BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OZngJnL-2R5m"
      },
      "outputs": [],
      "source": [
        "def scale_resize_image(image):\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32) # equivalent to dividing image pixels by 255\n",
        "    image = tf.image.resize(image, (INPUT_WIDTH, INPUT_HEIGHT)) # Resizing the image to 224x224 dimention\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "atZP6gmTdX_F"
      },
      "outputs": [],
      "source": [
        "def get_image_data(id_img_map, sample_id):\n",
        "  images = []\n",
        "  fs = id_img_map[sample_id]\n",
        "  for i,f in enumerate(fs[::-1]): # Reverse reversed time\n",
        "    image = np.load(f)\n",
        "    image_resized = scale_resize_image(image)\n",
        "    images.append(image_resized)\n",
        "  input = np.array(images)\n",
        "  return input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PK1SJLcb9Qg",
        "outputId": "2d1a8579-54d1-4986-b529-7051a9e3c11d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104/104 [02:46<00:00,  1.60s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def get_batch_data(batch):\n",
        "  X = []\n",
        "  y = []\n",
        "  for sample_id, label in batch:\n",
        "    id_img_map = id_img_map_positive if label==1 else id_img_map_negative\n",
        "    x = get_image_data(id_img_map, sample_id)\n",
        "    X.append(x)\n",
        "    y.append(label)\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "  return X, y\n",
        "\n",
        "train_data = []\n",
        "for batch in tqdm(train_batch_ids):\n",
        "  X, y = get_batch_data(batch)\n",
        "  train_data += [[X,y]]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataset(dataset, name):\n",
        "  for i, batch in enumerate(dataset):\n",
        "    X,y = batch\n",
        "    with open(f'data/TrainingData/{name}/{i}_X.npy', 'wb') as f:\n",
        "      np.save(f, X)\n",
        "    with open(f'data/TrainingData/{name}/{i}_y.npy', 'wb') as f:\n",
        "      np.save(f, y)"
      ],
      "metadata": {
        "id": "Yc3RgUHY5HHA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "for batch in tqdm(test_batch_ids):\n",
        "  X, y = get_batch_data(batch)\n",
        "  test_data += [[X,y]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ6cxdiB5X0O",
        "outputId": "37ec053b-2bb6-4de7-8337-83803942f4d1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [14:33<00:00, 24.97s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dataset(test_data, 'test')"
      ],
      "metadata": {
        "id": "KT9a6AUkE7VY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_batch(dataset_name, batch_no):\n",
        "  X = np.load(f'data/TrainingData/{dataset_name}/{batch_no}_X.npy')\n",
        "  y = np.load(f'data/TrainingData/{dataset_name}/{batch_no}_y.npy')\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "iyoJoVwvKG1Z"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Timestamp-averaged CNN model"
      ],
      "metadata": {
        "id": "uLL70nm2XY3G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "X5cByDMJEmhO"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv2D, BatchNormalization, \\\n",
        "    MaxPool2D, GlobalMaxPool2D\n",
        "\n",
        "# https://medium.com/smileinnovation/training-neural-network-with-image-sequence-an-example-with-video-as-input-c3407f7a0b0f\n",
        "\n",
        "def build_convnet(shape=(112, 112, 3)):\n",
        "    momentum = .9\n",
        "    model = keras.Sequential()\n",
        "    model.add(Conv2D(64, (3,3), input_shape=shape,\n",
        "        padding='same', activation='relu'))\n",
        "    # model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # model.add(MaxPool2D())\n",
        "    \n",
        "    # model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # model.add(MaxPool2D())\n",
        "    \n",
        "    # model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # model.add(MaxPool2D())\n",
        "    \n",
        "    # model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # flatten...\n",
        "    model.add(GlobalMaxPool2D())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3cuFOO-2qX1_"
      },
      "outputs": [],
      "source": [
        "from keras.layers import TimeDistributed, GRU, Dense, Dropout\n",
        "def action_model(shape=(5, 112, 112, 3), nbout=3):\n",
        "    # Create our convnet with (112, 112, 3) input shape\n",
        "    # convnet = build_convnet(shape)\n",
        "    \n",
        "    # then create our final model\n",
        "    model = build_convnet(shape)\n",
        "    # add the convnet with (5, 112, 112, 3) shape\n",
        "    # model.add(TimeDistributed(convnet, input_shape=shape))\n",
        "    # # here, you can also use GRU or LSTM\n",
        "    # model.add(GRU(64))\n",
        "    # and finally, we make a decision network\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(2, activation='relu'))\n",
        "    model.add(Dense(nbout, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "\n",
        "    # https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/\n",
        "    # model.add(TimeDistributed(Conv2D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,INPUT_WIDTH,INPUT_HEIGHT, N_CHANNELS)))\n",
        "    # model.add(TimeDistributed(Conv2D(filters=64, kernel_size=3, activation='relu')))\n",
        "    # model.add(TimeDistributed(Dropout(0.5)))\n",
        "    # model.add(TimeDistributed(MaxPool2D()))\n",
        "    # model.add(TimeDistributed(Flatten()))\n",
        "    # model.add(LSTM(100))\n",
        "    # model.add(Dropout(0.5))\n",
        "    # model.add(Dense(100, activation='relu'))\n",
        "    # model.add(Dense(n_outputs, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "NBFRAME = 6\n",
        "# INSHAPE=(NBFRAME,) + (INPUT_WIDTH, INPUT_HEIGHT) + (N_CHANNELS,) # (6, 128, 128, 12)\n",
        "INSHAPE= (INPUT_WIDTH, INPUT_HEIGHT) + (N_CHANNELS,) # (6, 128, 128, 12)\n",
        "model = action_model(INSHAPE, nbout=1)\n",
        "optimizer = keras.optimizers.Adam(1e-4)\n",
        "\n",
        "model.compile(\n",
        "    optimizer,\n",
        "    'binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DhYIl1BW-Tqr",
        "outputId": "09433326-727d-4e90-ae98-0ee2c6308ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 1\n",
            "Training: [0.6846197  0.56237981 0.56169325 0.66406167 0.57582922]\n",
            "Validating: [0.66136235 0.609375   0.57340318 0.64406888 0.68474359]\n",
            "\n",
            "EPOCH: 2\n",
            "Training: [0.67665922 0.57608173 0.57104279 0.65832966 0.60476259]\n",
            "Validating: [0.66171114 0.596875   0.56029454 0.64406888 0.69177483]\n",
            "\n",
            "EPOCH: 3\n",
            "Training: [0.67448851 0.5875     0.57760405 0.6647251  0.62103   ]\n",
            "Validating: [0.65816583 0.61875    0.58809862 0.63193653 0.69385253]\n",
            "\n",
            "EPOCH: 4\n",
            "Training: [0.66803063 0.6        0.606524   0.63133826 0.63605278]\n",
            "Validating: [0.65737942 0.609375   0.57528827 0.64448555 0.69703748]\n",
            "\n",
            "EPOCH: 5\n",
            "Training: [0.67782651 0.57884615 0.60085658 0.6639526  0.60473713]\n",
            "Validating: [0.65395042 0.64375    0.62385415 0.60517154 0.70318837]\n",
            "\n",
            "EPOCH: 6\n",
            "Training: [0.66136689 0.625      0.65050423 0.66886397 0.66673636]\n",
            "Validating: [0.6508723  0.6375     0.6121478  0.60517154 0.70763818]\n",
            "\n",
            "EPOCH: 7\n",
            "Training: [0.67174988 0.5890625  0.59390362 0.64187642 0.62635873]\n",
            "Validating: [0.64670607 0.6625     0.66196582 0.58735936 0.71701754]\n",
            "\n",
            "EPOCH: 8\n",
            "Training: [0.66762306 0.5796875  0.56685771 0.62882031 0.63874312]\n",
            "Validating: [0.64606048 0.65625    0.64704069 0.59990838 0.71376989]\n",
            "\n",
            "EPOCH: 9\n",
            "Training: [0.65786176 0.6171875  0.62050843 0.6277136  0.65786947]\n",
            "Validating: [0.64354442 0.6625     0.67219781 0.56288052 0.71384226]\n",
            "\n",
            "EPOCH: 10\n",
            "Training: [0.65809197 0.61706731 0.60953915 0.62304263 0.65675169]\n",
            "Validating: [0.640699   0.65       0.63600685 0.59402603 0.71428593]\n",
            "\n",
            "EPOCH: 11\n",
            "Training: [0.66692109 0.6015625  0.6382998  0.54139503 0.6446076 ]\n",
            "Validating: [0.64034797 0.640625   0.62174888 0.59928919 0.71134045]\n",
            "\n",
            "EPOCH: 12\n",
            "Training: [0.67069031 0.578125   0.59746728 0.55351027 0.61216912]\n",
            "Validating: [0.64036259 0.646875   0.62982095 0.59928919 0.71803941]\n",
            "\n",
            "EPOCH: 13\n",
            "Training: [0.64912029 0.63149039 0.62710844 0.63861211 0.67356781]\n",
            "Validating: [0.63841208 0.64375    0.62542535 0.59928919 0.71397399]\n",
            "\n",
            "EPOCH: 14\n",
            "Training: [0.66227051 0.609375   0.63593417 0.59212434 0.63620052]\n",
            "Validating: [0.64083768 0.646875   0.61942381 0.64714956 0.71133476]\n",
            "\n",
            "EPOCH: 15\n",
            "Training: [0.65580948 0.6296875  0.64408772 0.72137947 0.65656169]\n",
            "Validating: [0.65536643 0.59375    0.54979793 0.74131079 0.7098847 ]\n",
            "\n",
            "EPOCH: 16\n",
            "Training: [0.65952119 0.6125     0.61797108 0.63440296 0.65213769]\n",
            "Validating: [0.64060292 0.66875    0.66465341 0.59402603 0.71852633]\n",
            "\n",
            "EPOCH: 17\n",
            "Training: [0.65700516 0.621875   0.66570482 0.64417782 0.63830233]\n",
            "Validating: [0.65432304 0.609375   0.56480833 0.75748503 0.70293517]\n",
            "\n",
            "EPOCH: 18\n",
            "Training: [0.65250591 0.625      0.61784555 0.73729669 0.67206085]\n",
            "Validating: [0.63894954 0.665625   0.65845378 0.60116889 0.71811891]\n",
            "\n",
            "EPOCH: 19\n",
            "Training: [0.6329114  0.6546875  0.69617256 0.66954689 0.71953792]\n",
            "Validating: [0.63680602 0.6625     0.6514485  0.60783555 0.71929734]\n",
            "\n",
            "EPOCH: 20\n",
            "Training: [0.65190467 0.615625   0.64173082 0.60043292 0.66473826]\n",
            "Validating: [0.63349951 0.665625   0.65845378 0.60116889 0.71901457]\n",
            "\n",
            "EPOCH: 21\n",
            "Training: [0.64653356 0.665625   0.67553899 0.67325867 0.68705036]\n",
            "Validating: [0.63421289 0.65       0.63040949 0.62886119 0.71284644]\n",
            "\n",
            "EPOCH: 22\n",
            "Training: [0.63300971 0.640625   0.64940402 0.70071669 0.70356523]\n",
            "Validating: [0.63375739 0.640625   0.61370494 0.62886119 0.71194603]\n",
            "\n",
            "EPOCH: 23\n",
            "Training: [0.6314799  0.6421875  0.66070702 0.65066435 0.69986408]\n",
            "Validating: [0.62967327 0.675      0.67890836 0.58735936 0.72284069]\n",
            "\n",
            "EPOCH: 24\n",
            "Training: [0.62559088 0.6375     0.65497557 0.63167566 0.71658493]\n",
            "Validating: [0.62871857 0.671875   0.66577521 0.60783555 0.71748731]\n",
            "\n",
            "EPOCH: 25\n",
            "Training: [0.6490875  0.6171875  0.65465757 0.6227266  0.66144018]\n",
            "Validating: [0.63298376 0.65       0.62076521 0.65241272 0.70910797]\n",
            "\n",
            "EPOCH: 26\n",
            "Training: [0.64452429 0.6171875  0.63944123 0.64709356 0.66595273]\n",
            "Validating: [0.62941501 0.66875    0.69314686 0.54766749 0.720999  ]\n",
            "\n",
            "EPOCH: 27\n",
            "Training: [0.65316772 0.6203125  0.65166245 0.56485586 0.65742591]\n",
            "Validating: [0.62875118 0.665625   0.70226496 0.52257967 0.72840487]\n",
            "\n",
            "EPOCH: 28\n",
            "Training: [0.65541124 0.6078125  0.63302813 0.57806781 0.65306907]\n",
            "Validating: [0.63360627 0.646875   0.62122405 0.64126721 0.71648464]\n",
            "\n",
            "EPOCH: 29\n",
            "Training: [0.64638671 0.63125    0.62833451 0.70179183 0.68339082]\n",
            "Validating: [0.63574899 0.640625   0.60596199 0.66677169 0.71393559]\n",
            "\n",
            "EPOCH: 30\n",
            "Training: [0.63834257 0.63461539 0.65415963 0.67867478 0.67963149]\n",
            "Validating: [0.63223394 0.65       0.61680917 0.66677169 0.71407825]\n",
            "\n",
            "EPOCH: 31\n",
            "Training: [0.64305797 0.6375     0.64303331 0.6815808  0.68594137]\n",
            "Validating: [0.62870431 0.678125   0.67312081 0.60927786 0.72158204]\n",
            "\n",
            "EPOCH: 32\n",
            "Training: [0.63726605 0.6359375  0.71800421 0.54738237 0.71088253]\n",
            "Validating: [0.62816013 0.6625     0.69345572 0.52948766 0.72880428]\n",
            "\n",
            "EPOCH: 33\n",
            "Training: [0.65415325 0.6203125  0.62630502 0.64048944 0.6794309 ]\n",
            "Validating: [0.62658334 0.675      0.68437563 0.57625265 0.72150185]\n",
            "\n",
            "EPOCH: 34\n",
            "Training: [0.62820621 0.64050481 0.66107061 0.58878057 0.71092498]\n",
            "Validating: [0.62313162 0.6625     0.67723278 0.54958598 0.72771711]\n",
            "\n",
            "EPOCH: 35\n",
            "Training: [0.63557163 0.6359375  0.67071149 0.62228246 0.69937715]\n",
            "Validating: [0.62364997 0.684375   0.67643913 0.64369636 0.7262428 ]\n",
            "\n",
            "EPOCH: 36\n",
            "Training: [0.64620956 0.63581731 0.65017377 0.61637687 0.68793704]\n",
            "Validating: [0.62186388 0.68125    0.68724169 0.59546833 0.7290813 ]\n",
            "\n",
            "EPOCH: 37\n",
            "Training: [0.6600047  0.6140625  0.62456301 0.6334342  0.65594932]\n",
            "Validating: [0.62546353 0.684375   0.6812504  0.62363683 0.72948481]\n",
            "\n",
            "EPOCH: 38\n",
            "Training: [0.64110316 0.640625   0.65589557 0.64749872 0.69428698]\n",
            "Validating: [0.62350924 0.684375   0.6812504  0.62363683 0.72863711]\n",
            "\n",
            "EPOCH: 39\n",
            "Training: [0.63006698 0.6453125  0.65568714 0.64176321 0.70253891]\n",
            "Validating: [0.62511258 0.675      0.65744812 0.64223332 0.73226476]\n",
            "\n",
            "EPOCH: 40\n",
            "Training: [0.60599687 0.6734375  0.69809416 0.71823152 0.73290245]\n",
            "Validating: [0.62326437 0.6625     0.6336457  0.67531806 0.73246811]\n",
            "\n",
            "EPOCH: 41\n",
            "Training: [0.63792076 0.65625    0.67233631 0.66316211 0.69931247]\n",
            "Validating: [0.61802938 0.68125    0.67932732 0.61594453 0.73348969]\n",
            "\n",
            "EPOCH: 42\n",
            "Training: [0.63732731 0.6390625  0.64744487 0.60353615 0.68093228]\n",
            "Validating: [0.61922663 0.66875    0.70096986 0.53803402 0.73465861]\n",
            "\n",
            "EPOCH: 43\n",
            "Training: [0.62592385 0.6515625  0.68069802 0.56992388 0.70618164]\n",
            "Validating: [0.61846197 0.678125   0.66774887 0.6303035  0.73266168]\n",
            "\n",
            "EPOCH: 44\n",
            "Training: [0.63806082 0.63269231 0.65715396 0.68683044 0.68179039]\n",
            "Validating: [0.62073525 0.66875    0.63290933 0.69974788 0.73623158]\n",
            "\n",
            "EPOCH: 45\n",
            "Training: [0.63679291 0.65625    0.67082784 0.68231782 0.69811383]\n",
            "Validating: [0.61608857 0.684375   0.66619916 0.65473332 0.73804145]\n",
            "\n",
            "EPOCH: 46\n",
            "Training: [0.62611155 0.6671875  0.6579923  0.68659216 0.7146936 ]\n",
            "Validating: [0.61386232 0.690625   0.66908364 0.6744252  0.73693607]\n",
            "\n",
            "EPOCH: 47\n",
            "Training: [0.64201077 0.634375   0.66515022 0.66835257 0.68439491]\n",
            "Validating: [0.62017655 0.6625     0.61840042 0.7185469  0.73686063]\n",
            "\n",
            "EPOCH: 48\n",
            "Training: [0.64931956 0.6203125  0.62381245 0.64833832 0.6729381 ]\n",
            "Validating: [0.6155919  0.6875     0.70108975 0.59915799 0.74545696]\n",
            "\n",
            "EPOCH: 49\n",
            "Training: [0.65557099 0.6171875  0.65426992 0.56944565 0.65419089]\n",
            "Validating: [0.61678329 0.6875     0.6754462  0.64322017 0.74562348]\n",
            "\n",
            "EPOCH: 50\n",
            "Training: [0.61833584 0.696875   0.70867695 0.6948394  0.73831332]\n",
            "Validating: [0.61444323 0.684375   0.67185143 0.64322017 0.74370546]\n",
            "\n",
            "EPOCH: 51\n",
            "Training: [0.62790475 0.6453125  0.67524713 0.6235178  0.71134081]\n",
            "Validating: [0.61361116 0.671875   0.69819681 0.5522549  0.75219617]\n",
            "\n",
            "EPOCH: 52\n",
            "Training: [0.63664301 0.64375    0.68692878 0.58471321 0.71127814]\n",
            "Validating: [0.61211963 0.6875     0.67138523 0.65562618 0.7463711 ]\n",
            "\n",
            "EPOCH: 53\n",
            "Training: [0.61418453 0.6546875  0.67141787 0.68631354 0.7330352 ]\n",
            "Validating: [0.63011647 0.665625   0.60895827 0.80316846 0.74194782]\n",
            "\n",
            "EPOCH: 54\n",
            "Training: [0.65308088 0.6390625  0.63251512 0.68043249 0.68760979]\n",
            "Validating: [0.61893269 0.6375     0.69646827 0.41693149 0.74688025]\n",
            "\n",
            "EPOCH: 55\n",
            "Training: [0.6167731  0.66237981 0.69830102 0.57622051 0.72807937]\n",
            "Validating: [0.6085459  0.68125    0.66394933 0.64895951 0.745642  ]\n",
            "\n",
            "EPOCH: 56\n",
            "Training: [0.63809687 0.6515625  0.64661001 0.71214606 0.69351789]\n",
            "Validating: [0.6102044  0.6875     0.65320929 0.71411708 0.7476593 ]\n",
            "\n",
            "EPOCH: 57\n",
            "Training: [0.6386743  0.64002404 0.66875939 0.69213185 0.67962919]\n",
            "Validating: [0.61128014 0.690625   0.66192309 0.69490139 0.74882565]\n",
            "\n",
            "EPOCH: 58\n",
            "Training: [0.630072   0.6578125  0.66728062 0.69141914 0.70168157]\n",
            "Validating: [0.61162835 0.696875   0.70058501 0.62988683 0.74932211]\n",
            "\n",
            "EPOCH: 59\n",
            "Training: [0.62185446 0.6390625  0.68542158 0.63893393 0.70684486]\n",
            "Validating: [0.61684481 0.6875     0.63475247 0.76871607 0.74834357]\n",
            "\n",
            "EPOCH: 60\n",
            "Training: [0.62181841 0.6796875  0.67488967 0.71913953 0.72386098]\n",
            "Validating: [0.60928916 0.69375    0.69707623 0.62988683 0.75364237]\n",
            "\n",
            "EPOCH: 61\n",
            "Training: [0.6394019  0.6546875  0.66413087 0.65315859 0.69172187]\n",
            "Validating: [0.60888975 0.69375    0.69225168 0.62988683 0.7509324 ]\n",
            "\n",
            "EPOCH: 62\n",
            "Training: [0.60662615 0.68112981 0.71121504 0.61964443 0.73292463]\n",
            "Validating: [0.60676166 0.675      0.65278723 0.65436568 0.74938678]\n",
            "\n",
            "EPOCH: 63\n",
            "Training: [0.62104691 0.66658654 0.65983797 0.68055901 0.71161223]\n",
            "Validating: [0.60515581 0.678125   0.65538463 0.66865139 0.74953893]\n",
            "\n",
            "EPOCH: 64\n",
            "Training: [0.63300048 0.646875   0.6652092  0.66756911 0.68963096]\n",
            "Validating: [0.60255878 0.678125   0.65419416 0.67531806 0.75246153]\n",
            "\n",
            "EPOCH: 65\n",
            "Training: [0.63514198 0.6421875  0.6664622  0.63323918 0.68935312]\n",
            "Validating: [0.6028192  0.69375    0.67289089 0.67531806 0.7538997 ]\n",
            "\n",
            "EPOCH: 66\n",
            "Training: [0.62389601 0.6484375  0.67531836 0.64343236 0.71020822]\n",
            "Validating: [0.60425317 0.690625   0.66860745 0.67484187 0.75365804]\n",
            "\n",
            "EPOCH: 67\n",
            "Training: [0.62918666 0.67139423 0.68830105 0.68948099 0.69985154]\n",
            "Validating: [0.6105761  0.696875   0.64543334 0.78166662 0.75694156]\n",
            "\n",
            "EPOCH: 68\n",
            "Training: [0.63438663 0.640625   0.63688497 0.71565795 0.70371918]\n",
            "Validating: [0.60593301 0.690625   0.68868916 0.62462367 0.75424138]\n",
            "\n",
            "EPOCH: 69\n",
            "Training: [0.61108894 0.67415865 0.69189615 0.68832348 0.7160555 ]\n",
            "Validating: [0.60220201 0.690625   0.66497109 0.68109187 0.75788664]\n",
            "\n",
            "EPOCH: 70\n",
            "Training: [0.60276045 0.671875   0.6944478  0.65508929 0.74882969]\n",
            "Validating: [0.59930681 0.6875     0.68726059 0.61795701 0.75908603]\n",
            "\n",
            "EPOCH: 71\n",
            "Training: [0.63193201 0.6671875  0.68514561 0.63606122 0.70100278]\n",
            "Validating: [0.59902092 0.690625   0.68705517 0.63129034 0.75870541]\n",
            "\n",
            "EPOCH: 72\n",
            "Training: [0.63799148 0.6296875  0.65965967 0.65830839 0.67773153]\n",
            "Validating: [0.60514107 0.684375   0.64960984 0.71845291 0.75685858]\n",
            "\n",
            "EPOCH: 73\n",
            "Training: [0.63281357 0.659375   0.65157953 0.64266745 0.70219689]\n",
            "Validating: [0.60833954 0.6875     0.71867466 0.56460139 0.752931  ]\n",
            "\n",
            "EPOCH: 74\n",
            "Training: [0.60343194 0.6828125  0.71798754 0.6399484  0.73179427]\n",
            "Validating: [0.59995278 0.678125   0.64863554 0.68030755 0.75710878]\n",
            "\n",
            "EPOCH: 75\n",
            "Training: [0.60883286 0.690625   0.68014525 0.76257361 0.75536468]\n",
            "Validating: [0.59840313 0.6875     0.68038851 0.63129034 0.76146449]\n",
            "\n",
            "EPOCH: 76\n",
            "Training: [0.63284595 0.6484375  0.68418875 0.63251562 0.70039659]\n",
            "Validating: [0.59817823 0.690625   0.66847986 0.67405755 0.76169743]\n",
            "\n",
            "EPOCH: 77\n",
            "Training: [0.60035548 0.68125    0.70680357 0.66411271 0.74740288]\n",
            "Validating: [0.60101455 0.7125     0.66756091 0.76916662 0.76175972]\n",
            "\n",
            "EPOCH: 78\n",
            "Training: [0.60796757 0.6859375  0.70300784 0.74497316 0.73441934]\n",
            "Validating: [0.59557367 0.696875   0.66014261 0.74046049 0.7625813 ]\n",
            "\n",
            "EPOCH: 79\n",
            "Training: [0.61001338 0.66983173 0.6835254  0.71961759 0.72508712]\n",
            "Validating: [0.60460737 0.709375   0.65758584 0.7979004  0.76177922]\n",
            "\n",
            "EPOCH: 80\n",
            "Training: [0.60763786 0.6875     0.67959369 0.73236453 0.74945313]\n",
            "Validating: [0.59216664 0.703125   0.67407365 0.69890404 0.76526259]\n",
            "\n",
            "EPOCH: 81\n",
            "Training: [0.61230617 0.671875   0.68826607 0.65447068 0.72616909]\n",
            "Validating: [0.59546634 0.709375   0.66422757 0.76916662 0.76424205]\n",
            "\n",
            "EPOCH: 82\n",
            "Training: [0.60782321 0.66514423 0.64131801 0.71925021 0.72632992]\n",
            "Validating: [0.58968723 0.7        0.69266339 0.65624537 0.76629671]\n",
            "\n",
            "EPOCH: 83\n",
            "Training: [0.60571258 0.66358173 0.67449185 0.63458884 0.73511709]\n",
            "Validating: [0.59585082 0.696875   0.73242424 0.57126806 0.76296773]\n",
            "\n",
            "EPOCH: 84\n",
            "Training: [0.62723665 0.659375   0.68574423 0.63699649 0.71084612]\n",
            "Validating: [0.58995372 0.690625   0.65923078 0.69364088 0.76798541]\n",
            "\n",
            "EPOCH: 85\n",
            "Training: [0.61214688 0.6671875  0.65553174 0.71327755 0.73593051]\n",
            "Validating: [0.58903246 0.69375    0.6687806  0.68072422 0.767361  ]\n",
            "\n",
            "EPOCH: 86\n",
            "Training: [0.61307641 0.67836539 0.70074515 0.74034798 0.72166233]\n",
            "Validating: [0.59588348 0.709375   0.662828   0.77541662 0.7652977 ]\n",
            "\n",
            "EPOCH: 87\n",
            "Training: [0.62294652 0.653125   0.66770063 0.71795546 0.71309153]\n",
            "Validating: [0.58973035 0.684375   0.65923078 0.67405755 0.76665586]\n",
            "\n",
            "EPOCH: 88\n",
            "Training: [0.59254145 0.703125   0.71673853 0.69775418 0.75816428]\n",
            "Validating: [0.5876094  0.7        0.67083334 0.715614   0.76564611]\n",
            "\n",
            "EPOCH: 89\n",
            "Training: [0.62115012 0.665625   0.67001424 0.73093255 0.72132468]\n",
            "Validating: [0.59060948 0.715625   0.66599568 0.78166662 0.76929339]\n",
            "\n",
            "EPOCH: 90\n",
            "Training: [0.61804767 0.6734375  0.68989233 0.69924339 0.71086373]\n",
            "Validating: [0.59279529 0.715625   0.66607397 0.7979004  0.76911076]\n",
            "\n",
            "EPOCH: 91\n",
            "Training: [0.61511302 0.675      0.68671569 0.70602709 0.72623391]\n",
            "Validating: [0.59159344 0.7        0.73381119 0.57793473 0.77187794]\n",
            "\n",
            "EPOCH: 92\n",
            "Training: [0.64504137 0.63197115 0.65683945 0.60288957 0.68600905]\n",
            "Validating: [0.58973279 0.7        0.68968418 0.66455197 0.77015245]\n",
            "\n",
            "EPOCH: 93\n",
            "Training: [0.61770606 0.65769231 0.64127453 0.65637701 0.72207769]\n",
            "Validating: [0.59351945 0.7        0.72871837 0.58969943 0.76730587]\n",
            "\n",
            "EPOCH: 94\n",
            "Training: [0.60159507 0.7015625  0.71673173 0.68917982 0.7522587 ]\n",
            "Validating: [0.5851495  0.7        0.67509929 0.69466162 0.77006097]\n",
            "\n",
            "EPOCH: 95\n",
            "Training: [0.61718165 0.665625   0.67309869 0.6612456  0.72541715]\n",
            "Validating: [0.59112143 0.696875   0.71762529 0.58969943 0.76753876]\n",
            "\n",
            "EPOCH: 96\n",
            "Training: [0.58736685 0.703125   0.74521123 0.65239366 0.75980451]\n",
            "Validating: [0.59686739 0.69375    0.6388875  0.81365797 0.76943961]\n",
            "\n",
            "EPOCH: 97\n",
            "Training: [0.60695156 0.69086539 0.67576035 0.78049717 0.74034719]\n",
            "Validating: [0.58358804 0.69375    0.67687584 0.66981513 0.77122585]\n",
            "\n",
            "EPOCH: 98\n",
            "Training: [0.59686295 0.7078125  0.74120816 0.69039121 0.74486093]\n",
            "Validating: [0.58896708 0.703125   0.65683213 0.78450754 0.77286023]\n",
            "\n",
            "EPOCH: 99\n",
            "Training: [0.63123871 0.64375    0.64730364 0.72918642 0.70230468]\n",
            "Validating: [0.58575503 0.7        0.65658023 0.76543486 0.77660339]\n",
            "\n",
            "EPOCH: 100\n",
            "Training: [0.6183138  0.65       0.68555392 0.63256646 0.71586892]\n",
            "Validating: [0.58785967 0.690625   0.65996661 0.71469551 0.77245982]\n",
            "\n",
            "EPOCH: 101\n",
            "Training: [0.62225588 0.6625     0.64868995 0.69879475 0.7188428 ]\n",
            "Validating: [0.58719565 0.703125   0.68759077 0.67648179 0.7731716 ]\n",
            "\n",
            "EPOCH: 102\n",
            "Training: [0.60678537 0.675      0.67519613 0.68108858 0.7282762 ]\n",
            "Validating: [0.58272451 0.703125   0.69617747 0.65689846 0.77610533]\n",
            "\n",
            "EPOCH: 103\n",
            "Training: [0.6141871  0.659375   0.67925931 0.71209978 0.73254165]\n",
            "Validating: [0.57939388 0.7        0.67414836 0.69852126 0.77764534]\n",
            "\n",
            "EPOCH: 104\n",
            "Training: [0.62227046 0.6609375  0.66747547 0.6555994  0.70736508]\n",
            "Validating: [0.58499693 0.7        0.70300061 0.62347171 0.77465484]\n",
            "\n",
            "EPOCH: 105\n",
            "Training: [0.62005514 0.67259615 0.69741899 0.69373561 0.72012312]\n",
            "Validating: [0.5810639  0.709375   0.6725398  0.75341105 0.77965789]\n",
            "\n",
            "EPOCH: 106\n",
            "Training: [0.62785582 0.65625    0.6830045  0.71651543 0.69865868]\n",
            "Validating: [0.58663252 0.71875    0.67426365 0.77784087 0.77984872]\n",
            "\n",
            "EPOCH: 107\n",
            "Training: [0.60533414 0.68125    0.68019591 0.71373459 0.73208173]\n",
            "Validating: [0.58283108 0.70625    0.68732601 0.69708586 0.77584769]\n",
            "\n",
            "EPOCH: 108\n",
            "Training: [0.61448315 0.646875   0.66904933 0.67781215 0.73746024]\n",
            "Validating: [0.5865945  0.71875    0.67093032 0.78409087 0.77824308]\n",
            "\n",
            "EPOCH: 109\n",
            "Training: [0.61815948 0.69290865 0.68310513 0.74335847 0.73826585]\n",
            "Validating: [0.58463108 0.703125   0.72296003 0.60467269 0.77502627]\n",
            "\n",
            "EPOCH: 110\n",
            "Training: [0.59457136 0.68461539 0.70364121 0.72127952 0.75885991]\n",
            "Validating: [0.58568941 0.728125   0.67564933 0.81123373 0.78625092]\n",
            "\n",
            "EPOCH: 111\n",
            "Training: [0.60939126 0.6734375  0.68242394 0.71681567 0.73150038]\n",
            "Validating: [0.57790626 0.70625    0.67059175 0.73960153 0.78392736]\n",
            "\n",
            "EPOCH: 112\n",
            "Training: [0.60812403 0.67836539 0.68013989 0.72202041 0.74250693]\n",
            "Validating: [0.5799408  0.703125   0.68814203 0.67750253 0.77980309]\n",
            "\n",
            "EPOCH: 113\n",
            "Training: [0.593413   0.696875   0.6997522  0.70464025 0.75953737]\n",
            "Validating: [0.57530399 0.690625   0.67717466 0.6497556  0.77523077]\n",
            "\n",
            "EPOCH: 114\n",
            "Training: [0.59789003 0.684375   0.72626611 0.66530307 0.74959573]\n",
            "Validating: [0.57748441 0.703125   0.66575175 0.74486468 0.77921858]\n",
            "\n",
            "EPOCH: 115\n",
            "Training: [0.6041797  0.684375   0.69023572 0.71619744 0.74534816]\n",
            "Validating: [0.57740392 0.696875   0.66980923 0.70662534 0.77735408]\n",
            "\n",
            "EPOCH: 116\n",
            "Training: [0.593845   0.6875     0.70266631 0.66132529 0.75377817]\n",
            "Validating: [0.57934996 0.703125   0.70330803 0.64387325 0.77066587]\n",
            "\n",
            "EPOCH: 117\n",
            "Training: [0.60203999 0.6703125  0.68344191 0.71420646 0.72726596]\n",
            "Validating: [0.60511693 0.690625   0.62618452 0.858613   0.78390695]\n",
            "\n",
            "EPOCH: 118\n",
            "Training: [0.59223742 0.690625   0.67863898 0.79564197 0.75214275]\n",
            "Validating: [0.5767764  0.69375    0.6784638  0.66742477 0.77452641]\n",
            "\n",
            "EPOCH: 119\n",
            "Training: [0.59641839 0.68076923 0.70420525 0.70253507 0.74826727]\n",
            "Validating: [0.57431147 0.715625   0.67190477 0.7711742  0.78764779]\n",
            "\n",
            "EPOCH: 120\n",
            "Training: [0.64242697 0.65       0.62670398 0.68430187 0.69618785]\n",
            "Validating: [0.5739096  0.709375   0.70365485 0.65887841 0.78130924]\n",
            "\n",
            "EPOCH: 121\n",
            "Training: [0.61943115 0.6515625  0.69612188 0.61364878 0.7219647 ]\n",
            "Validating: [0.57653175 0.70625    0.67611345 0.72668486 0.78541909]\n",
            "\n",
            "EPOCH: 122\n",
            "Training: [0.61535932 0.665625   0.66669907 0.6925539  0.72734383]\n",
            "Validating: [0.5764456  0.703125   0.68785617 0.67421932 0.78299736]\n",
            "\n",
            "EPOCH: 123\n",
            "Training: [0.60559275 0.6921875  0.6989523  0.69619879 0.74047202]\n",
            "Validating: [0.5761078  0.7        0.67181038 0.71335153 0.78435258]\n",
            "\n",
            "EPOCH: 124\n",
            "Training: [0.59668648 0.684375   0.72147067 0.67954924 0.75116621]\n",
            "Validating: [0.58077178 0.725      0.67615153 0.7979004  0.78582059]\n",
            "\n",
            "EPOCH: 125\n",
            "Training: [0.59656043 0.7046875  0.72848066 0.70953914 0.754733  ]\n",
            "Validating: [0.57978726 0.715625   0.74854084 0.60467269 0.77347496]\n",
            "\n",
            "EPOCH: 126\n",
            "Training: [0.59129578 0.69915865 0.70513282 0.69387951 0.75227927]\n",
            "Validating: [0.5705677  0.696875   0.66919037 0.70662534 0.78558838]\n",
            "\n",
            "EPOCH: 127\n",
            "Training: [0.59334117 0.696875   0.70204403 0.70900809 0.74836886]\n",
            "Validating: [0.57599307 0.7125     0.66563275 0.78403135 0.78923061]\n",
            "\n",
            "EPOCH: 128\n",
            "Training: [0.60012498 0.69362981 0.69233405 0.76570621 0.74616975]\n",
            "Validating: [0.57240552 0.7125     0.66774765 0.77784087 0.79223169]\n",
            "\n",
            "EPOCH: 129\n",
            "Training: [0.60938777 0.6828125  0.6977848  0.69363008 0.73915746]\n",
            "Validating: [0.56678922 0.696875   0.68166237 0.66796932 0.78629271]\n",
            "\n",
            "EPOCH: 130\n",
            "Training: [0.60800185 0.67259615 0.69042103 0.6833849  0.7290991 ]\n",
            "Validating: [0.57214166 0.715625   0.66981765 0.78597057 0.79449013]\n",
            "\n",
            "EPOCH: 131\n",
            "Training: [0.6144047  0.6859375  0.69611111 0.69933708 0.73070638]\n",
            "Validating: [0.56990378 0.7125     0.70364982 0.66796932 0.784693  ]\n",
            "\n",
            "EPOCH: 132\n",
            "Training: [0.60006124 0.6671875  0.67025178 0.67378192 0.73818026]\n",
            "Validating: [0.56835154 0.690625   0.66989496 0.68136218 0.78888852]\n",
            "\n",
            "EPOCH: 133\n",
            "Training: [0.6114633  0.684375   0.6940338  0.70063614 0.74604931]\n",
            "Validating: [0.57237141 0.709375   0.66517848 0.77784087 0.79524156]\n",
            "\n",
            "EPOCH: 134\n",
            "Training: [0.60004807 0.6875     0.67934971 0.75674423 0.74179405]\n",
            "Validating: [0.57113065 0.71875    0.7341453  0.64452634 0.77993692]\n",
            "\n",
            "EPOCH: 135\n",
            "Training: [0.60636748 0.67019231 0.68451507 0.71887117 0.74014185]\n",
            "Validating: [0.56981321 0.7125     0.67154667 0.77159087 0.79792681]\n",
            "\n",
            "EPOCH: 136\n",
            "Training: [0.57562967 0.7046875  0.72233316 0.71584785 0.77729185]\n",
            "Validating: [0.56429091 0.7        0.67996437 0.68901569 0.7889398 ]\n",
            "\n",
            "EPOCH: 137\n",
            "Training: [0.58318624 0.703125   0.69524175 0.74676195 0.76769316]\n",
            "Validating: [0.56227824 0.70625    0.67835193 0.7276717  0.79340295]\n",
            "\n",
            "EPOCH: 138\n",
            "Training: [0.59821609 0.696875   0.68115009 0.79705987 0.74911381]\n",
            "Validating: [0.56021442 0.715625   0.71369462 0.66130265 0.78967992]\n",
            "\n",
            "EPOCH: 139\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-df6959e00856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mepoch_batch_nos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_batch_nos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCHES_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_batch_nos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# print(X.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-350896e9de6e>\u001b[0m in \u001b[0;36mload_batch\u001b[0;34m(dataset_name, batch_no)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'data/TrainingData/{dataset_name}/{batch_no}_X.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'data/TrainingData/{dataset_name}/{batch_no}_y.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 441\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "EPOCHS = 200\n",
        "BATCHES_PER_EPOCH = 20\n",
        "\n",
        "all_batch_nos = list(range(104))\n",
        "for e in range(EPOCHS):\n",
        "  print('\\nEPOCH:', e+1)\n",
        "  train_stats = []\n",
        "  epoch_batch_nos = np.random.choice(all_batch_nos, BATCHES_PER_EPOCH, replace=False)\n",
        "  for i in epoch_batch_nos:\n",
        "    X,y = load_batch('train', i)\n",
        "    X = np.mean(X, axis=1)\n",
        "    # print(X.shape)\n",
        "    # print('Training:', model.predict_on_batch(X))\n",
        "    batch_stats = model.train_on_batch(X, y)\n",
        "    train_stats.append(batch_stats)\n",
        "  print('Training:', np.mean(train_stats, axis=0))\n",
        "  val_stats = []\n",
        "  for i in range(10):\n",
        "    X,y = load_batch('val', i)\n",
        "    X = np.mean(X, axis=1)\n",
        "    batch_stats = model.test_on_batch(X, y)\n",
        "    val_stats.append(batch_stats)\n",
        "  print('Validating:', np.mean(val_stats, axis=0))\n",
        "\n",
        "print('\\n\\nDONE TRAINING.')\n",
        "for i in range(35):\n",
        "  X,y = load_batch('val', i)\n",
        "  X = np.mean(X, axis=1)\n",
        "  print('Validating:', model.test_on_batch(X, y, return_dict=True))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('models/t_averaged_cnn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdFZXt1oZ3_m",
        "outputId": "8d1df644-1d8c-46ab-fab7-fd1ddc0e22ee"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/t_averaged_cnn/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Channel-histogram CNN-LSTM model"
      ],
      "metadata": {
        "id": "3m11K376XdTH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "EGk_huV0acqM"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv1D, BatchNormalization, \\\n",
        "    MaxPool1D, GlobalMaxPool1D\n",
        "\n",
        "# https://medium.com/smileinnovation/training-neural-network-with-image-sequence-an-example-with-video-as-input-c3407f7a0b0f\n",
        "\n",
        "def build_convnet(shape=(112, 112, 3)):\n",
        "    momentum = .9\n",
        "    model = keras.Sequential()\n",
        "    model.add(Conv1D(64, 3, input_shape=shape,\n",
        "        padding='same', activation='relu'))\n",
        "    # model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # model.add(MaxPool2D())\n",
        "    \n",
        "    # model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "     \n",
        "    # model.add(MaxPool2D())\n",
        "    \n",
        "    # model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # model.add(MaxPool2D())\n",
        "    \n",
        "    # model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # flatten...\n",
        "    # model.add(GlobalMaxPool1D())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zv5YlyCacqN",
        "outputId": "c37cfe41-0060-40d0-b7af-d482dacc6c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 32, 12)\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import TimeDistributed, LSTM, Dense, Dropout\n",
        "def action_model(shape=(5, 112, 112, 3), nbout=3):\n",
        "    # Create our convnet with (112, 112, 3) input shape\n",
        "    # convnet = build_convnet(shape)\n",
        "    \n",
        "    # then create our final model\n",
        "    # convnet = build_convnet(shape[1:])\n",
        "    # print(convnet.summary())\n",
        "\n",
        "    model = keras.Sequential()\n",
        "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=shape))\n",
        "    # model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
        "    model.add(TimeDistributed(Dropout(0.5)))\n",
        "    model.add(TimeDistributed(MaxPool1D(pool_size=2)))\n",
        "    model.add(TimeDistributed(GlobalMaxPool1D()))\n",
        "    model.add(LSTM(64))\n",
        "    model.add(Dropout(0.5))\n",
        "    # model.add(Dense(100, activation='relu'))\n",
        "    # model.add(Dense(n_outputs, activation='softmax'))\n",
        "    # # add the convnet with (5, 112, 112, 3) shape\n",
        "    # model.add(TimeDistributed(convnet, input_shape=shape))\n",
        "    # # here, you can also use GRU or LSTM\n",
        "    # model.add(GRU(64))\n",
        "    # and finally, we make a decision network\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(2, activation='relu'))\n",
        "    model.add(Dense(nbout, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "\n",
        "    # https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/\n",
        "    # model.add(TimeDistributed(Conv2D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,INPUT_WIDTH,INPUT_HEIGHT, N_CHANNELS)))\n",
        "    # model.add(TimeDistributed(Conv2D(filters=64, kernel_size=3, activation='relu')))\n",
        "    # model.add(TimeDistributed(Dropout(0.5)))\n",
        "    # model.add(TimeDistributed(MaxPool2D()))\n",
        "    # model.add(TimeDistributed(Flatten()))\n",
        "    # model.add(LSTM(100))\n",
        "    # model.add(Dropout(0.5))\n",
        "    # model.add(Dense(100, activation='relu'))\n",
        "    # model.add(Dense(n_outputs, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "NBFRAME = 6\n",
        "INSHAPE=(NBFRAME,) + (32,) + (N_CHANNELS,) # (6, 128, 128, 12)\n",
        "# INSHAPE= (32,) + (N_CHANNELS,) # (6, 128, 128, 12)\n",
        "print(INSHAPE)\n",
        "model = action_model(INSHAPE, nbout=1)\n",
        "optimizer = keras.optimizers.Adam(1e-4)\n",
        "\n",
        "model.compile(\n",
        "    optimizer,\n",
        "    'binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "964b8a2d-1d26-4deb-83fe-df30c8f238f5",
        "id": "hd3HUn56acqN"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 1\n",
            "Training: [0.70627557 0.5078125  0.49602589 0.58131348 0.51188537]\n",
            "\n",
            "EPOCH: 2\n",
            "Training: [0.70465723 0.515625   0.51169368 0.52893237 0.5026588 ]\n",
            "\n",
            "EPOCH: 3\n",
            "Training: [0.70598189 0.484375   0.48379602 0.52744944 0.49911648]\n",
            "\n",
            "EPOCH: 4\n",
            "Training: [0.69585466 0.5296875  0.54685862 0.57717874 0.53817243]\n",
            "\n",
            "EPOCH: 5\n",
            "Training: [0.70581698 0.478125   0.47209753 0.49129212 0.48212802]\n",
            "\n",
            "EPOCH: 6\n",
            "Training: [0.70303938 0.46875    0.49209905 0.46081402 0.46821645]\n",
            "\n",
            "EPOCH: 7\n",
            "Training: [0.69908733 0.51947115 0.51648903 0.47958186 0.53680509]\n",
            "\n",
            "EPOCH: 8\n",
            "Training: [0.69771644 0.509375   0.52086316 0.48016148 0.51702967]\n",
            "\n",
            "EPOCH: 9\n",
            "Training: [0.70382934 0.5109375  0.48467928 0.42680395 0.47667662]\n",
            "\n",
            "EPOCH: 10\n",
            "Training: [0.70497007 0.4953125  0.49354042 0.43048947 0.47699436]\n",
            "\n",
            "EPOCH: 11\n",
            "Training: [0.69582818 0.484375   0.52675763 0.42479821 0.5003361 ]\n",
            "\n",
            "EPOCH: 12\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-e86be4cbe285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNBFRAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           histogram, _ = np.histogram(\n\u001b[0;32m---> 18\u001b[0;31m               \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m           )\n\u001b[1;32m     20\u001b[0m           \u001b[0mhistograms_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ravel_and_check_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m     \u001b[0mbin_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniform_bins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_bin_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;31m# Histogram is an integer or a float array depending on the weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36m_get_bin_edges\u001b[0;34m(a, bins, range, weights)\u001b[0m\n\u001b[1;32m    446\u001b[0m         bin_edges = np.linspace(\n\u001b[1;32m    447\u001b[0m             \u001b[0mfirst_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_equal_bins\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             endpoint=True, dtype=bin_type)\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbin_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfirst_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_equal_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/function_base.py\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;31m# In-place multiplication y *= delta/div is faster, but prevents the multiplicant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m# from overriding what class is produced, and thus prevents, e.g. use of Quantities,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "EPOCHS = 200\n",
        "BATCHES_PER_EPOCH = 20\n",
        "\n",
        "all_batch_nos = list(range(104))\n",
        "for e in range(EPOCHS):\n",
        "  print('\\nEPOCH:', e+1)\n",
        "  train_stats = []\n",
        "  epoch_batch_nos = np.random.choice(all_batch_nos, BATCHES_PER_EPOCH, replace=False)\n",
        "  for i_epoch in epoch_batch_nos:\n",
        "    X,y = load_batch('train', i_epoch)\n",
        "    histograms_batch = []\n",
        "    for i_sample in range(X.shape[0]):\n",
        "      histograms_sample = []\n",
        "      for channel in range(N_CHANNELS):\n",
        "        histograms_frame = []\n",
        "        for frame in range(NBFRAME):\n",
        "          histogram, _ = np.histogram(\n",
        "              X[i_sample,frame,:,:,channel], bins=32, range=(0, 0.3)\n",
        "          )\n",
        "          histograms_frame.append([histogram])\n",
        "        histograms_frame = np.concatenate(histograms_frame, axis=0).T\n",
        "        histograms_sample.append([histograms_frame])\n",
        "      histograms_sample = np.concatenate(histograms_sample, axis=0).T\n",
        "      histograms_batch.append([histograms_sample])\n",
        "    histograms_batch = np.concatenate(histograms_batch, axis=0)\n",
        "    batch_stats = model.train_on_batch(histograms_batch, y)\n",
        "    train_stats.append(batch_stats)\n",
        "  print('Training:', np.mean(train_stats, axis=0))\n",
        "#   val_stats = []\n",
        "#   for i in range(10):\n",
        "#     X,y = load_batch('val', i)\n",
        "#     X = np.mean(X, axis=1)\n",
        "#     batch_stats = model.test_on_batch(X, y)\n",
        "#     val_stats.append(batch_stats)\n",
        "#   print('Validating:', np.mean(val_stats, axis=0))\n",
        "\n",
        "# print('\\n\\nDONE TRAINING.')\n",
        "# for i in range(35):\n",
        "#   X,y = load_batch('val', i)\n",
        "#   X = np.mean(X, axis=1)\n",
        "#   print('Validating:', model.test_on_batch(X, y, return_dict=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjdnE42Lkc_o"
      },
      "outputs": [],
      "source": [
        "model.save('models/channel_hist_lstm')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "TrainModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}